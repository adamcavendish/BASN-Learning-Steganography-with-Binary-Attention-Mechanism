\section{Experiments}

\subsection{Experiments Configurations}

To demonstrate the effectiveness of our model, we conducted experiments on ImageNet dataset~\cite{ImageNet}. Specially, ILSVRC2012 dataset with 1,281,167 images is used for training and 50,000 for testing. Our work is trained on one NVidia GTX1080 GPU and we adopt a batch size of 32 for all models. Optimizers and learning rate setup for ITC model, MFD model \(1^{st}\) phase and MFD model \(2^{nd}\) phase are Adam optimizer~\cite{Adam} with 0.01, Nesterov momentum optimizer~\cite{Nesterov} with 1e-5 and Adam optimizer with 0.01 respectively.

All the validation processes use the compressed version of \textit{The Complete Works of William Shakespeare}~\cite{Shakespeare} provided by Project Gutenberg~\cite{Gutenberg}. It is downloaded here at~\cite{GutenbergShakespeare}.

The error rate uses BSER (Bit Steganography Error Rate) shown in Equation~\ref{eq:BSER}.

\begin{equation}
  \text{BSER} = \frac{\text{Number of redundant bits or missing bits}}{\text{Number of hidden information bits}} \times 100\%
  \label{eq:BSER}
\end{equation}

\subsection{Different Embedding Strategies Comparison}

Table~\ref{tab:diff_strategies_comparison} presents a performance comparison among different fusion strategies and different inference techniques. These techniques offer several ways to trade off between error rate and payload capacity. With \textit{Permutative Straddling}, it is further possible to precisely handle the payload capacity during transmission.

\begin{table}
  \centering
  \begin{tabular}{lrr}
    \toprule
    Model             & BSER (\%) & Payload (bpp) \\
    \midrule
    Min-LSM-1         & 1.06\%    & 1.29          \\
    Min-LSM-2         & 0.67\%    & 0.42          \\
    Mean-LSM-1        & 2.22\%    & 3.89          \\
    Mean-LSM-2        & 3.14\%    & 2.21          \\
    Min-LSM-1-PS-0.6  & 0.74\%    & 0.80          \\
    Min-LSM-1-PS-0.8  & 0.66\%    & 0.80          \\
    Mean-LSM-1-PS-1.2 & 0.82\%    & 1.20          \\
    Mean-LSM-2-PS-1.2 & 0.93\%    & 1.20          \\
    \bottomrule
  \end{tabular}
  \caption{Different Embedding Strategies Comparison}%
  \label{tab:diff_strategies_comparison}
  \vspace{\baselineskip}
  In the model name part, the value after LSM is the number of bits masked during embedding process and the value after PS is the maximum payload capacity the embedded image is limited to during permutative straddling.
\end{table}

\figureSteganographyResultMeanLSMOne%

\subsection{Steganalysis Experiments}

To ensure that our model is robust to steganalysis methods, we test our models using StegExpose~\cite{StegExpose} with linear interpolation of detection threshold from 0.00 to 1.00 with 0.01 as the step interval. The ROC curve is shown in Figure~\ref{fig:roc_curves} where true positive stands for an embedded image correctly identified that there are hidden data inside while false positive means that a clean figure is falsely classified as an embedded image. The figure shows a comparison among our several models, StegNet~\cite{StegNet} and Baluja-2017~\cite{HIPS} plotted in dash-line-connected scatter data. It demonstrates that StegExpose can only work a little better than random guessing and most BASN models perform better than StegNet and Baluja-2017.

Our model is also further examined with learning-based steganalysis methods~\cite{SPAM,SRM,Yedroudj}. All of these models are trained with our cover and embedded images.Their corresponding ROC curves are shown in Figure~\ref{fig:roc_curves}. SRM~\cite{SRM} method works quite well on our model with a larger payload capacity, however in real-world applications we can always keep our dataset private and thus ensuring high security in resisting detection from learning-based steganalysis methods.

\figureROCCurves%

\subsection{Feature Distortion Analysis}

Figure~\ref{fig:basn_feature_distortion_rate} shows that our model has very little influence on targeted neural-network-automated tasks, which in this case is classification. Most embedded images, even carrying with more than 3 bpp of hidden information, takes an average of only 2\% distortion.

\figureBASNFeatureDistortionRate%
